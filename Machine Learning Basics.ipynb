{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The point of the jupyter notebook is to give some toy code to play with the concepts in section 5.1 - 5.4 in Goodfellow's book.\n",
    "\n",
    "As usual, Shift + Enter runs a block of code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.1 Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{5.1.4}$ Example: Linear Regression\n",
    "\n",
    "Learner: $$\\pmb{y} = \\beta \\pmb{1_m} + w_1 \\pmb{x_1} + ... w_n \\pmb{x_n}$$\n",
    "where $\\beta$ (bias) and $w_i$ are scalar parameters (to fit), and $\\pmb{y, x_i} \\in \\mathbb{R}^{m \\times 1}$ for $i$ = 1,2,..,$n$ are the target and feature columns, respectively, of the given data.\n",
    "\n",
    "The following will build a model for predicting housing prices in the Boston area. \n",
    "\n",
    "We first need to import all necessary python modules with their usual nicknames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we load in our dataset for housing prices in Boston with 10 predictors. As an example, we print the second data entry (remember, Python is 0-indexed). Notice that it is an array of 13 values, so our data is 13-dimensional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.7310e-02, 0.0000e+00, 7.0700e+00, 0.0000e+00, 4.6900e-01,\n",
       "       6.4210e+00, 7.8900e+01, 4.9671e+00, 2.0000e+00, 2.4200e+02,\n",
       "       1.7800e+01, 3.9690e+02, 9.1400e+00])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston = load_boston()\n",
    "boston.data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And view the second target value (i.e. home price) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.6"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.target[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we separate our data and target into easier variable names, and use a built-in `sklearn` function to split our data for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = boston.data\n",
    "y = boston.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've loaded and split our data, we need to define our model. Luckily, `sklearn` has an easy syntax for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create an instance of a Linear Regressor\n",
    "linreg = linear_model.LinearRegression(fit_intercept=True, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\nabla_{\\pmb{w}} \\text{MSE}_\\text{train} = 0 $$\n",
    "\n",
    "$$ \\Rightarrow \\nabla_{\\pmb{w}} \\, \\frac{1}{m} \\, || \\, \\widehat{\\pmb{y}}^\\text{(train)} - \\pmb{y}^\\text{(train)} \\, ||_2^2 = 0 $$\n",
    "\n",
    "$$ \\Rightarrow \\pmb{w} = (\\pmb{X}^{\\text{(train)} \\, \\top} \\pmb{X}^\\text{(train)})^{-1} \\pmb{X}^{\\text{(train)} \\, \\top} \\pmb{y}^\\text{(train)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the above model is untrained (i.e. it is just a theoretical model with arbitrary parameters). We now train our model on our specific training dataset. Note: If you are using the online version of the jupyter notebook, this fitting might take a couple seconds)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit the model using the training data\n",
    "linreg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have our machine learning algorithm! Given a new 13-dimensional datapoint, we could predict what the target might be. But as with any algorithm, it always helps to check how accurate you expect it to be. Run the following code to generate a mean squared error on both the training data (we expect this to be nice always) and the test data (this could be bad if our model is overfitted)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between prediction and target\n",
      "(Mean Squared) Train Error:  21.555648194527308\n",
      "(Mean Squared) Test Error:  24.31823830917051  (estimated Generalization Error)\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = linreg.predict(X_train)\n",
    "y_test_pred = linreg.predict(X_test)\n",
    "print(\"MSE between prediction and target\")\n",
    "print(\"(Mean Squared) Train Error: \", mean_squared_error(y_train, y_train_pred))\n",
    "print(\"(Mean Squared) Test Error: \", mean_squared_error(y_test, y_test_pred), \" (estimated Generalization Error)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.2 Capacity, Overfitting, and Underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increased Capacity (e.g. quadratic features): $$\\pmb{y} = \\beta \\pmb{1_m} + w_1 \\pmb{x_1} + ... w_n \\pmb{x_n} + \\sum_{i}^{n} \\sum_{j}^{n} w_{in + j} \\pmb{x_i x_j}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2\n",
    "poly2 = PolynomialFeatures(n,include_bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly2_X_train = poly2.fit_transform(X_train)\n",
    "poly2_X_test = poly2.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg.fit(poly2_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = linreg.predict(poly2_X_train)\n",
    "y_test_pred = linreg.predict(poly2_X_test)\n",
    "print(\"MSE between prediction and target\")\n",
    "print(\"Train Error: \", mean_squared_error(y_train, y_train_pred))\n",
    "print(\"Test Error: \", mean_squared_error(y_test, y_test_pred), \" (estimated Generalization Error)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_n_err = np.empty(shape=(0,3))\n",
    "\n",
    "poly_order = 8\n",
    "for i in range(1,poly_order):\n",
    "    poly = PolynomialFeatures(i,include_bias=False)\n",
    "\n",
    "    poly_X_train = poly.fit_transform(X_train)\n",
    "    poly_X_test = poly.fit_transform(X_test)\n",
    "\n",
    "    linreg.fit(poly_X_train, y_train)\n",
    "    \n",
    "    y_train_pred = linreg.predict(poly_X_train)\n",
    "    y_test_pred = linreg.predict(poly_X_test)\n",
    "\n",
    "    train_err = mean_squared_error(y_train, y_train_pred)\n",
    "    test_err = mean_squared_error(y_test, y_test_pred)\n",
    "    score = r2_score(y_test, y_test_pred)\n",
    "\n",
    "    poly_n_err = np.append(poly_n_err, np.array([[train_err, test_err, score]]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(poly_n_err[:, :2])\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.spines['top'].set_color('none')\n",
    "ax.spines['bottom'].set_color('none')\n",
    "ax.spines['left'].set_color('none')\n",
    "ax.spines['right'].set_color('none')\n",
    "ax.tick_params(labelcolor='w', top=False, bottom=False, left=False, right=False)\n",
    "\n",
    "plt.subplots_adjust(wspace=0.7)\n",
    "\n",
    "ax1 = fig.add_subplot(131)\n",
    "ax1.plot(range(1,poly_order), poly_n_err[:,0])\n",
    "plt.xticks(range(1,poly_order))\n",
    "plt.title('Train')\n",
    "plt.ylim([0, 25])\n",
    "\n",
    "ax2 = fig.add_subplot(132)\n",
    "ax2.plot(range(1,poly_order), poly_n_err[:,1],'orange')\n",
    "plt.xticks(range(1,poly_order))\n",
    "plt.yticks(range(0,23,5))\n",
    "plt.title('Test')\n",
    "plt.ylim([0, 25])\n",
    "\n",
    "ax3 = fig.add_subplot(133)\n",
    "ax3.plot(range(1,poly_order), poly_n_err[:,1],'orange')\n",
    "plt.xticks(range(1,poly_order))\n",
    "plt.title('Test')\n",
    "\n",
    "ax.set_xlabel('polynomial order')\n",
    "ax.set_ylabel('mean-squared error')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.3 Hyperparameters and Validation Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularization: Minimmize $$J(\\pmb{w}) = \\text{MSE}_\\text{train} + \\lambda \\pmb{w}^T \\pmb{w} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import linear regressor with l2 regularization\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha = lambda = 1.0\n",
    "linreg_Ridge = linear_model.Ridge(alpha=1.0, fit_intercept=True, normalize=True, tol=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the 7th order polynomial\n",
    "linreg_Ridge.fit(poly_X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = linreg_Ridge.predict(poly_X_train)\n",
    "y_test_pred = linreg_Ridge.predict(poly_X_test)\n",
    "print(\"MSE between prediction and target for 7th degree features\")\n",
    "print(\"Train Error: \", mean_squared_error(y_train, y_train_pred))\n",
    "print(\"Test Error: \", mean_squared_error(y_test, y_test_pred), \" (estimated Generalization Error)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_err = np.empty(shape=(0,3))\n",
    "\n",
    "reg_max = 3.0\n",
    "for i in np.arange(0,reg_max,0.1):\n",
    "    \n",
    "    linreg_Ridge = linear_model.Ridge(alpha=i, fit_intercept=True, normalize=True, tol=1e-4)\n",
    "\n",
    "    linreg_Ridge.fit(poly_X_train, y_train)\n",
    "    \n",
    "    y_train_pred = linreg_Ridge.predict(poly_X_train)\n",
    "    y_test_pred = linreg_Ridge.predict(poly_X_test)\n",
    "\n",
    "    train_err = mean_squared_error(y_train, y_train_pred)\n",
    "    test_err = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "    reg_err = np.append(reg_err, np.array([[i,train_err, test_err]]), axis=0)\n",
    "    \n",
    "min_test_err_id = np.where(reg_err[:,2]==min(reg_err[:,2]))[0][0]\n",
    "alpha_min = reg_err[min_test_err_id,0]\n",
    "print(reg_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.spines['top'].set_color('none')\n",
    "ax.spines['bottom'].set_color('none')\n",
    "ax.spines['left'].set_color('none')\n",
    "ax.spines['right'].set_color('none')\n",
    "ax.tick_params(labelcolor='w', top=False, bottom=False, left=False, right=False)\n",
    "\n",
    "plt.subplots_adjust(wspace=0.7)\n",
    "\n",
    "ax1 = fig.add_subplot(131)\n",
    "ax1.plot(reg_err[:,0], reg_err[:,1])\n",
    "plt.xticks([0, 1, 2, 3])\n",
    "plt.yticks(range(5,30,2))\n",
    "plt.title('Train')\n",
    "\n",
    "ax2 = fig.add_subplot(132)\n",
    "ax2.plot(reg_err[:,0], reg_err[:,2],'orange')\n",
    "plt.xticks([0, 1, 2, 3])\n",
    "#plt.yticks(range(5,30,2))\n",
    "plt.title('Test')\n",
    "plt.ylim([0, 29])\n",
    "\n",
    "ax2 = fig.add_subplot(133)\n",
    "ax2.plot(reg_err[:,0], reg_err[:,2],'orange')\n",
    "plt.xticks([0, 1, 2, 3])\n",
    "#plt.yticks(range(5,30,2))\n",
    "plt.title('Test')\n",
    "\n",
    "ax.set_xlabel('regularization parameter')\n",
    "ax.set_ylabel('mean-squared error')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_num = 10\n",
    "n_errs = np.empty(shape=(1,split_num))\n",
    "\n",
    "kf = KFold(n_splits = split_num)\n",
    "kf.get_n_splits(poly_X_train)\n",
    "\n",
    "linreg_Ridge_opt = linear_model.Ridge(alpha = alpha_min, fit_intercept=True, normalize=True, tol=1e-4)\n",
    "\n",
    "i = 0\n",
    "for train_index, test_index in kf.split(poly_X_train, y_train):\n",
    "    linreg_Ridge_opt.fit(poly_X_train[train_index],y_train[train_index])\n",
    "    n_errs[0,i] = mean_squared_error(y_train[test_index], linreg_Ridge_opt.predict(poly_X_train[test_index]))\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(n_errs)\n",
    "print(sum(n_errs[0])/len(n_errs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
