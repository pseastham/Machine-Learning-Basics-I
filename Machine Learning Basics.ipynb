{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The point of the jupyter notebook is to give some toy code to play with the concepts in section 5.1 - 5.4 in Goodfellow's book.\n",
    "\n",
    "As usual, Shift + Enter runs a block of code.\n",
    "\n",
    "** STILL NEED TO THINK OF SOME HOMEWORK PRO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.1 Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{5.1.4}$ Example: Linear Regression\n",
    "\n",
    "Learner: $$\\pmb{y} = \\beta \\pmb{1_m} + w_1 \\pmb{x_1} + ... w_n \\pmb{x_n}$$\n",
    "where $\\beta$ (bias) and $w_i$ are scalar parameters (to fit), and $\\pmb{y, x_i} \\in \\mathbb{R}^{m \\times 1}$ for $i$ = 1,2,..,$n$ are the target and feature columns, respectively, of the given data.\n",
    "\n",
    "The following will build a model for predicting housing prices in the Boston area. \n",
    "\n",
    "We first need to import all necessary python modules with their usual nicknames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we load in our dataset for housing prices in Boston with 13 predictors. As an example, we print the second data entry (remember, Python is 0-indexed). Notice that it is an array of 13 values, so our data is 13-dimensional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "boston.data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And view the second target value (i.e. home price) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston.target[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we separate our data and target into easier variable names, and use a built-in `sklearn` function to split our data for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = boston.data\n",
    "y = boston.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've loaded and split our data, we need to define our model. Luckily, `sklearn` has an easy syntax for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create an instance of a Linear Regressor\n",
    "linreg = linear_model.LinearRegression(fit_intercept=True, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\nabla_{\\pmb{w}} \\text{MSE}_\\text{train} = 0 $$\n",
    "\n",
    "$$ \\Rightarrow \\nabla_{\\pmb{w}} \\, \\frac{1}{m} \\, || \\, \\widehat{\\pmb{y}}^\\text{(train)} - \\pmb{y}^\\text{(train)} \\, ||_2^2 = 0 $$\n",
    "\n",
    "$$ \\Rightarrow \\pmb{w} = (\\pmb{X}^{\\text{(train)} \\, \\top} \\pmb{X}^\\text{(train)})^{-1} \\pmb{X}^{\\text{(train)} \\, \\top} \\pmb{y}^\\text{(train)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the above model is untrained (i.e. it is just a theoretical model with arbitrary parameters). We now train our model on our specific training dataset. Note: If you are using the online version of the jupyter notebook, this fitting might take a couple seconds)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have our machine learning algorithm! Given a new 13-dimensional datapoint, we could predict what the target might be. But as with any algorithm, it always helps to check how accurate you expect it to be. Run the following code to generate a mean squared error on both the training data (we expect this to be nice always) and the test data (this could be bad if our model is overfitted)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = linreg.predict(X_train)\n",
    "y_test_pred = linreg.predict(X_test)\n",
    "print(\"MSE between prediction and target\")\n",
    "print(\"(Mean Squared) Train Error: \", mean_squared_error(y_train, y_train_pred))\n",
    "print(\"(Mean Squared) Test Error: \", mean_squared_error(y_test, y_test_pred), \" (estimated Generalization Error)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** INCLUDE INTERPRETATION OF MEAN SQUARED ERROR. WHAT DOES THIS MEAN? **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.2 Capacity, Overfitting, and Underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increased Capacity (e.g. quadratic features): $$\\pmb{y} = \\beta \\pmb{1_m} + w_1 \\pmb{x_1} + ... w_n \\pmb{x_n} + \\sum_{i}^{n} \\sum_{j}^{n} w_{in + j} \\pmb{x_i x_j}$$\n",
    "\n",
    "The following gives an example of overfitting and underfitting, as controlled by the capacity of a model.\n",
    "\n",
    "First, we import a necessary module for handling polynomials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a polynomial of degree `n`; the default is a quadratic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2\n",
    "poly2 = PolynomialFeatures(n,include_bias=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train our data from the boston dataset defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly2_X_train = poly2.fit_transform(X_train)\n",
    "poly2_X_test = poly2.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "like before, now that we have defined our model theoretically, we need to actually fit for our constant coefficients (this might take a second if you are running this online)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg.fit(poly2_X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And our model is trained! To see how it performs, we need to analyze the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = linreg.predict(poly2_X_train)\n",
    "y_test_pred = linreg.predict(poly2_X_test)\n",
    "print(\"MSE between prediction and target\")\n",
    "print(\"Train Error: \", mean_squared_error(y_train, y_train_pred))\n",
    "print(\"Test Error: \", mean_squared_error(y_test, y_test_pred), \" (estimated Generalization Error)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see how increasing the capacity affects these errors, we create learners for many different polynomial orders to see how the error changes. If you are online, this will take a minute to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_n_err = np.empty(shape=(0,3))      # initialize 0x3 array to save three different \n",
    "                                        # types of errors for each polynomial order\n",
    "poly_order = 8   # max polynomial order \n",
    "for i in range(1,poly_order):  # create and obtain errors for polynomial learners of various capacity (polynomial order)\n",
    "    poly = PolynomialFeatures(i,include_bias=False)\n",
    "\n",
    "    poly_X_train = poly.fit_transform(X_train)\n",
    "    poly_X_test = poly.fit_transform(X_test)\n",
    "\n",
    "    linreg.fit(poly_X_train, y_train)\n",
    "    \n",
    "    y_train_pred = linreg.predict(poly_X_train)\n",
    "    y_test_pred = linreg.predict(poly_X_test)\n",
    "\n",
    "    train_err = mean_squared_error(y_train, y_train_pred)\n",
    "    test_err = mean_squared_error(y_test, y_test_pred)\n",
    "    score = r2_score(y_test, y_test_pred)\n",
    "\n",
    "    poly_n_err = np.append(poly_n_err, np.array([[train_err, test_err, score]]), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize how our model performs as we vary the polynomial order, we plot the error and score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(poly_n_err[:, :2])\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.spines['top'].set_color('none')\n",
    "ax.spines['bottom'].set_color('none')\n",
    "ax.spines['left'].set_color('none')\n",
    "ax.spines['right'].set_color('none')\n",
    "ax.tick_params(labelcolor='w', top=False, bottom=False, left=False, right=False)\n",
    "\n",
    "fig.set_figwidth(13)\n",
    "\n",
    "ax1 = fig.add_subplot(141)\n",
    "ax1.plot(range(1,poly_order), poly_n_err[:,0],'o-')\n",
    "plt.xticks(range(1,poly_order))\n",
    "plt.title('Train')\n",
    "plt.ylim([0, 25])\n",
    "\n",
    "ax2 = fig.add_subplot(142)\n",
    "ax2.plot(range(1,poly_order), poly_n_err[:,1],'o-')\n",
    "plt.xticks(range(1,poly_order))\n",
    "plt.yticks(range(0,23,5))\n",
    "plt.title('Test')\n",
    "plt.ylim([0, 25])\n",
    "\n",
    "ax3 = fig.add_subplot(143)\n",
    "ax3.plot(range(1,poly_order), poly_n_err[:,1],'o-')\n",
    "plt.xticks(range(1,poly_order))\n",
    "plt.title('')\n",
    "\n",
    "ax4 = fig.add_subplot(144)\n",
    "ax4.plot(range(1,poly_order), poly_n_err[:,2],'o-')\n",
    "plt.xticks(range(1,poly_order))\n",
    "ax4.set_ylabel('score')\n",
    "plt.title('Test')\n",
    "plt.ylim([0, 25])\n",
    "\n",
    "ax.set_xlabel('polynomial order')\n",
    "ax.set_ylabel('mean-squared error')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** WE SHOULD INCLUDE SOME INTERPRETATION OF THE ABOVE PLOTS **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.3 Hyperparameters and Validation Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularization: Minimize $$J(\\pmb{w}) = \\text{MSE}_\\text{train} + \\lambda \\pmb{w}^T \\pmb{w} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to import linear regressor with $l_2$ regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a 'ridge' model which....does something.  $\\alpha = \\lambda = 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_Ridge = linear_model.Ridge(alpha=1.0, fit_intercept=True, normalize=True, tol=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit the 7th order polynomial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_Ridge.fit(poly_X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we evaluate our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = linreg_Ridge.predict(poly_X_train)\n",
    "y_test_pred = linreg_Ridge.predict(poly_X_test)\n",
    "print(\"MSE between prediction and target for 7th degree features\")\n",
    "print(\"Train Error: \", mean_squared_error(y_train, y_train_pred))\n",
    "print(\"Test Error: \", mean_squared_error(y_test, y_test_pred), \" (estimated Generalization Error)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like before, we want to know how varying the hyperparameter impacts our error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_err = np.empty(shape=(0,3))\n",
    "\n",
    "reg_max = 3.0\n",
    "for i in np.arange(0,reg_max,0.1):\n",
    "    \n",
    "    linreg_Ridge = linear_model.Ridge(alpha=i, fit_intercept=True, normalize=True, tol=1e-4)\n",
    "\n",
    "    linreg_Ridge.fit(poly_X_train, y_train)\n",
    "    \n",
    "    y_train_pred = linreg_Ridge.predict(poly_X_train)\n",
    "    y_test_pred = linreg_Ridge.predict(poly_X_test)\n",
    "\n",
    "    train_err = mean_squared_error(y_train, y_train_pred)\n",
    "    test_err = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "    reg_err = np.append(reg_err, np.array([[i,train_err, test_err]]), axis=0)\n",
    "    \n",
    "min_test_err_id = np.where(reg_err[:,2]==min(reg_err[:,2]))[0][0]\n",
    "alpha_min = reg_err[min_test_err_id,0]\n",
    "print(reg_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and plot the errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.spines['top'].set_color('none')\n",
    "ax.spines['bottom'].set_color('none')\n",
    "ax.spines['left'].set_color('none')\n",
    "ax.spines['right'].set_color('none')\n",
    "ax.tick_params(labelcolor='w', top=False, bottom=False, left=False, right=False)\n",
    "\n",
    "plt.subplots_adjust(wspace=0.7)\n",
    "\n",
    "ax1 = fig.add_subplot(131)\n",
    "ax1.plot(reg_err[:,0], reg_err[:,1])\n",
    "plt.xticks([0, 1, 2, 3])\n",
    "plt.yticks(range(5,30,2))\n",
    "plt.title('Train')\n",
    "\n",
    "ax2 = fig.add_subplot(132)\n",
    "ax2.plot(reg_err[:,0], reg_err[:,2],'orange')\n",
    "plt.xticks([0, 1, 2, 3])\n",
    "#plt.yticks(range(5,30,2))\n",
    "plt.title('Test')\n",
    "plt.ylim([0, 29])\n",
    "\n",
    "ax2 = fig.add_subplot(133)\n",
    "ax2.plot(reg_err[:,0], reg_err[:,2],'orange')\n",
    "plt.xticks([0, 1, 2, 3])\n",
    "#plt.yticks(range(5,30,2))\n",
    "plt.title('Test')\n",
    "\n",
    "ax.set_xlabel('regularization parameter')\n",
    "ax.set_ylabel('mean-squared error')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and this shows...something"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-fold Cross-Validation\n",
    "\n",
    "An algorithmic way to cross-validate your learner is with the `k-fold cross-validation` algorith, which is given in the Goodfellow book. Luckily, `sklearn` has this algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run this cross-validation with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_num = 10\n",
    "n_errs = np.empty(shape=(1,split_num))\n",
    "\n",
    "kf = KFold(n_splits = split_num)\n",
    "kf.get_n_splits(poly_X_train)\n",
    "\n",
    "linreg_Ridge_opt = linear_model.Ridge(alpha = alpha_min, fit_intercept=True, normalize=True, tol=1e-4)\n",
    "\n",
    "i = 0\n",
    "for train_index, test_index in kf.split(poly_X_train, y_train):\n",
    "    linreg_Ridge_opt.fit(poly_X_train[train_index],y_train[train_index])\n",
    "    n_errs[0,i] = mean_squared_error(y_train[test_index], linreg_Ridge_opt.predict(poly_X_train[test_index]))\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now when we look at the errors...something happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(n_errs)\n",
    "print(sum(n_errs[0])/len(n_errs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see....something happens?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
